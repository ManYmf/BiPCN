# 进度

### v1版本

成功建立了最基本的两层模型，完成了框架搭建。

#### v1.visual

针对权重进行可视化，监督训练效果。

#### v1.1

增加偏置项可选功能，使用use_bias开关。

发现问题：AND问题必须启用偏置项，否则任务无法完成。其原因大概是因为如果没有偏置项，决策边界一直过原点，没有普适性。

### v2版本

成功将网络扩展到3层，并修复了一个问题：训练过程中的准确率统计，实际上是作弊式的统计，因为强制往目标方向靠了，所以我们在此时也应该调用model.predict来统计。

### v2.visual

继续可视化效果

#### v2.accuracy

尝试修复了一个问题：训练过程中的准确率统计，实际上是作弊式的统计，因为强制往目标方向靠了，所以我们在此时也应该调用model.predict来统计。

但我也不确定究竟有没有修复好，暂时不管这个功能了

#### v2.test

对于有一些随机种子出现了训练不达标的问题，我现在要来解决这个问题

- 第一步，测试100个种子的结果
- 第二步，发现结果中有79%的种子可以

根据豆包的解释，这只是对初值有些敏感罢了，不必多虑

1. 试了一下**Xavier 初始化**，对42可以了，不过对整体好像一般，还是80%正确率。
2. 尝试一下L2正则化，这下成功率直接变成0%，告辞

那就这样吧，先忙别的去了。

#### v2.cross

试了一下交叉熵损失，仍然没用，彻底忙别的去了

### v3

进入批处理版本，老问题，挑随机种子，解决一下

### v4

此次使用将数据转移至GPU，没什么大问题，只是训练轮次需要更多次

### v5

第一次成功手写出MNIST 97.5%！庆祝一下

不过对于CIFAR还是不太能够work，不知道原因是什么

#### v5_benchmark

这一项是为对比目前这个代码的性能，目前来看只比MLP多两倍速度，不慌

几个数据集的测试也大多不错。

### v6

开启genPC的工程，API风格尽量统一，方便合并。

### v10

让GPT修改代码，使其“更符合论文”，具体效果非常好，达到了手搓风味版差一点点的效果。

#### v10.1

尝试写BiPCN，具体效果有待观察
